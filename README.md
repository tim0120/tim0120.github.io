Hi, I'm Tim.

I'm a researcher interested in understanding how machine learning models learn and process information.

Currently, I'm working on language model interpretability in the Algorithmic Alignment Group; check out [my Master's thesis](https://dspace.mit.edu/handle/1721.1/156804) on some of the work! I'm also working on a mechanistic interpretability project [SPAR](https://sparai.org/).

### Projects/Research
A mix of the projects and research that I've done. Feel free to reach out to chat about any of it!
- My Master's Thesis: [Inverse Constitutional AI](https://dspace.mit.edu/handle/1721.1/156804)
- [The Effect of Activation Functions On Superposition in Toy Models](https://deep-learning-mit.github.io/staging/blog/2023/superposition/) (with [Vedang Lad](https://www.vedanglad.com/))
- [Iterative Interactive Inverse Constitutional AI (I^3CAI)](https://tim0120.github.io/files/i3cai.pdf) (with [Julian Manyika](https://www.linkedin.com/in/julianmanyika444/), [code and figures](https://github.com/jmanyika/interactive-cai))
- [RL-Augmented Action Spaces in MsPacman](https://tim0120.github.io/files/mspacman.pdf) (for [6.8200](https://pulkitag.github.io/6.8200/), with [Julian Yocum](https://twitter.com/julianyocum?lang=en), [code to play](https://github.com/JulianYocum/rl-pacman))

### Info
- This is my [resume](https://tim0120.github.io/files/resume.pdf).
- I'm a member of the [Algorithmic Alignment Group](https://algorithmicalignment.csail.mit.edu/team/).

### "Social" Media
- [twitter](https://twitter.com/timkostolansky)
- [gh](https://github.com/tim0120)
- [in](https://www.linkedin.com/in/kostolansky/)
